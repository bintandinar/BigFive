import numpy as np
import pandas as pd
from tqdm import tqdm

import re
import string

import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer  
stop_words = stopwords.words('english')


from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix,classification_report
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix,classification_report

import matplotlib.pyplot as plt
import seaborn as sns

from datasets import load_dataset
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder


pip install datasets scikit-learn


from datasets import load_dataset

# Memuat dataset dari Hugging Face
dataset = load_dataset("dair-ai/emotion", trust_remote_code=True)

# Memeriksa data yang dimuat
print(dataset)


# Memeriksa label yang tersedia dalam dataset
train_data = dataset['train']
print(train_data.features['label'].names)


# Memuat dataset dari Hugging Face
dataset = load_dataset("dair-ai/emotion")

# Menggabungkan data latih dan validasi
data = dataset['train']
texts = data['text']
labels = data['label']

# TF-IDF vektorizer
max_features = 10000  # Jumlah kata unik yang akan digunakan
tfidf_vectorizer = TfidfVectorizer(max_features=max_features)
x_data = tfidf_vectorizer.fit_transform(texts).toarray()

# Mengubah label menjadi bentuk numerik
label_encoder = LabelEncoder()
y_data = label_encoder.fit_transform(labels)

# K-Fold Cross Validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)
accuracies = []

for train_index, val_index in kf.split(x_data):
    x_train, x_val = x_data[train_index], x_data[val_index]
    y_train, y_val = y_data[train_index], y_data[val_index]
    
    # Membuat model Random Forest
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(x_train, y_train)
    
    # Prediksi dan evaluasi
    y_pred = model.predict(x_val)
    accuracy = accuracy_score(y_val, y_pred)
    accuracies.append(accuracy)
    print(f'Fold accuracy: {accuracy:.4f}')

# Rata-rata akurasi
print(f'Mean accuracy: {np.mean(accuracies):.4f}')


# Classification report untuk data validasi terakhir
final_y_pred = model.predict(x_val)
class_names = [str(i) for i in label_encoder.classes_]
final_report = classification_report(y_val, final_y_pred, target_names=class_names)
print('---------------------------------------------------------')
print('Classification Report for Final Validation Set:')
print(final_report)


# Confusion matrix
cnf_matrix = confusion_matrix(y_val, final_y_pred)

# Create labels for heatmap
group_names = ['TN','FP','FN','TP']
group_counts = ["{0:0.0f}".format(value) for value in cnf_matrix.flatten()]
labels = np.array(group_counts).reshape(cnf_matrix.shape)

# Display confusion matrix as heatmap
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(7, 5))
sns.heatmap(cnf_matrix, annot=labels, fmt='', cmap='Blues')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix for Final Validation Set')
plt.show()


# Visualisasi akurasi untuk setiap fold
plt.figure(figsize=(10, 6))
plt.plot(range(1, kf.get_n_splits() + 1), accuracies, marker='o', linestyle='--')
plt.title('K-Fold Cross Validation Accuracies')
plt.xlabel('Fold')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.grid(True)
plt.show()



